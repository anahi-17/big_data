Index

- [Introduction](#Introduction)
- [Theoretical framework of algorithms ](#Theoretical_framework_of_algorithms)
- [SVM ](#SVM)
- [Decision Tree](#Decision_Tree)
- [Logistic Regression](#Logistic_Regression)
- [Multilayer perceptron](#Multilayer_perceptron)
- [Implementation ](#Implementation)
- [Conclusions](#Conclusions)
- [References ](#References)

## Introduction
This document proposes the use of different machine learning algorithms (machine learning) as they are very common in solving a problem. A brief explanation of what each algorithm consists of as well as application examples will be given.
When comparing the results generated by these 4 machine learning algorithms, we will be able to know with which one is more effective when analyzing the data.
On the other hand we will be able to evaluate the measurement of the precision of the algorithms and the comparison of this precision.
When more than two algorithms are compared, it is necessary to take into account the problems of our datasets so that in each algorithm certain parameters are adjusted to obtain results.
In this document we will take the information from the data that is related to direct marketing campaigns of a Portuguese banking institution. 
Marketing campaigns were based on phone calls. Often, more than one contact with the same client was required, to access whether the product (term bank deposit) would be (or not) subscribed [12].
Input variables:
Bank client data:
1 - age (numeric)
2 - job: type of job (categorical: "administrator", "unknown", "unemployed", "management", "domestic worker", "entrepreneur", "student",
"worker", "self-employed", "retired", "technician", "services")
3 - marital: marital status (categorical: "married", "divorced", "single"; note: "divorced" means divorced or widowed)
4 - education (categorical: "unknown", "secondary", "primary", "tertiary")
5 - default: do you have credit in default? (binary: "yes", "no")
6 - balance: average annual balance, in euros (numeric)
7 - home: do you have a home loan? (binary: "yes", "no")
8 - loan: do you have a personal loan? (binary: "yes", "no")
related to the last contact of the current campaign:
9 - contact: type of contact communication (categorical: "unknown", "telephone", "mobile")
10 days: last contact day of the month (numeric)
11 months: last contact of the year of the year (categorical: "Jan", "Feb", "Mar", ..., "Nov", "Dec")
12 - duration: duration of the last contact, in seconds (numeric)
other attributes:
13 - campaign: number of contacts made during this campaign and for this customer (numeric, includes the last contact)
14 days: number of days that passed after the customer was contacted for the last time since a previous campaign (numeric, -1 means that the client was not previously contacted)
15 - previous: number of contacts made before this campaign and for this client (numerical)
16 - poutcome: result of the marketing campaign previous (categorical: "unknown", "other", "failure", "success")
Output variable (desired goal):
17 - and - does the client Have you signed a term deposit? (binary: "yes", "no")
The data we use is found in [13]. 

The algorithms used for this work are the following:
Support Vector Machine (SVM).
Decision Tree.
Logistic Regression.
Multilayer Perceptron.

## Theoretical framework of algorithms
### SVM
A support vector machine (SVM) is a supervised learning algorithm that can be used for binary classification or regression. The SVM theory is based on the idea of ‚Äã‚Äãstructural risk minimization in [7] is a brief explanation of this. An SVM first maps the entry points to a feature space of a larger dimension and finds a hyperplane that separates them and maximizes the margin m between classes in this space. The SVM finds the optimal hyperplane using the dot product with functions in the feature space that are called kernels. The optimal hyperplane solution can be written as the combination of a few entry points that are called support vectors. [6] An application example is found in [8], other examples are applications such as natural language processing, speech, image recognition, and machine vision.

### Decision Tree

The decision tree classifier is one of the possible approaches to multi-stage decision making; table search rules, conversion of decision table to optimal decision trees and sequential approaches are others. The basic idea involved in any multi-stage approach is to divide a complex decision into a union of several simpler decisions, waiting for the final solution obtained in this way would resemble the desired desired solution. A complete multi-stage review. The recognition schemes are given by Dattatreya and Kanal [6]. Hierarchical classifiers allow the rejection of class labels at intermediate stages.
The steps can be summarized as follows:
Dividimos the data in two or more sets based homogeneous differentiator most significant input variables. 
The decision tree identifies the most significant variable and its value that provides the best homogeneous population sets. 
All input variables and all possible division points are evaluated and the one with the best result is chosen.

### Logistic Regression 

Is a classification algorithm that is used to predict the probability of a categorical dependent variable (a predictive analysis). In logistic regression, the dependent variable is a binary variable that contains data encoded as 1 - 0, yes - no, open - closed, etc.
Logistic regression is used to describe data and explain the relationship between a dependent binary variable and one or more independent nominal, ordinal, interval, or ratio level variables [11].
As mentioned in the introduction, the fit of this model is important. Adding independent variables to a logistic regression model will always increase the amount of variance explained in the log probabilities (generally expressed as R¬≤). However, adding more and more variables to the model can result in an overfit, reducing the generalizability of the model beyond the data that the model fits into.
This algorithm helps us to know the probability of whether an example belongs to a class or not, we are going to use the inverse of the logit function and what we can call as the logistic function and in many cases also named as the sigmoid function by a representation in form of S:
ùúô (ùëß) = 11 + ùëí ‚àí ùëß
Here we can indicate that z is the input to the network and results from the linear combination of the weights and the respective characteristics of each example, that is, z = wT
x = w0 + w1x1 + ... + wmxm. Each characteristic will have a weight because each one of them will influence more or less for the final decision of which class it belongs to [14].

### Multilayer perceptron

The perceptron is very useful for classifying data sets that are linearly separable. They encounter serious limitations with data sets that do not fit this pattern as discovered with the XOR problem.  Logic functions typically have two inputs and one output that depends on the values ‚Äã‚Äãof the inputs. The inputs and outputs can take two values: True and False, or 0 and 1. Thus for each logical function there is a table that indicates what the output will be given the combination of the input values [9].
The multilayer perceptron (MLP) breaks this constraint and classifies data sets that are not linearly separable. The Perceptron consists of an input layer and an output layer that are fully connected. MLPs have the same input and output layers, but can have multiple layers hidden between the layers mentioned above.
Steps to develop the MLP:
The inputs are pushed forward through the MLP by taking the input point product with the weights between the input layer and the hidden layer (WH). This point product produces a value in the hidden layer. 
MLPs use trigger functions in each of their calculated layers. You push the calculated output on the current layer through a trigger function.
Once the calculated output in the hidden layer has been pushed through the trigger function, push it to the next layer in the MLP by taking the dot product with the corresponding weights.
Repeat steps two and three until you reach the output layer.
In the output layer, the calculations will either be used for a backpropagation algorithm that corresponds to the trigger function that was selected for the MLP (in the case of training) or a decision will be made based on the result (in the case of the test) [10].

## Implementation
The tools used here are Spark with the Scala language. Below we show what each one consists of.

Scala is a programming language designed to program using patterns in a concise way. In the same way, it integrates principles of object orientation and functional programming, allowing programmers to be more productive.
Among its advantages we can highlight thatis written less code compared to other languages, which allows us to have fewer bugs and make it much easier to read and understand. 

Spark is one of the most widely used Big Data technologies worldwide, used by large corporations, small businesses and academia. It is a is a platform that is oriented to handle large volumes of distributed data that offers us several advantages and reduces execution times. 
Spark offers us an interactive shell in Scala with which we can experiment and test, testing all the API that the framework offers us.

## Results

The following table shows the results of 10 iterations with each of the algorithms, the first is SVM, which showed no change with 88% accuracy, the second is Decision Tree in which the results were more noticeable, varying between the 88% and 89% accuracy, in the following two algorithms which are Logistic regression and Multilayer Perceptron there was no change in accuracy, showing their result with 88%.
<p align="center">
<img width="450"
src=https://i0.wp.com/www.aprendemachinelearning.com/wp-content/uploads/2017/11/icon_algoritmos_regresion.png?resize=300%2C150&ssl=1
raw=true">
</p> 


The following table shows the execution time of each of the algorithms mentioned above.
SVM had a minimal variation between 10 and 12 seconds, dominating the runtime of 11 seconds, Decision Tree from 11 to 15 seconds, Logistic Regression from 10 to 12 seconds, as well as SVM dominating 11 seconds, and Multilayer perceptron from 11-14 seconds.
<p align="center">
<img width="450"
src=https://i0.wp.com/www.aprendemachinelearning.com/wp-content/uploads/2017/11/icon_algoritmos_regresion.png?resize=300%2C150&ssl=1
raw=true">
</p> 
         
## Conclusions
Through the comparative classification study that was carried out, we were able to identify the precision measure of the algorithms and the comparison of this precision. 
The main thing that we observed in the tables is that the Decision Tree algorithm is more effective when analyzing the data with 89% accuracy and the lowest was SVM with 88% accuracy. On the other hand, we evaluate the execution time in which the one with the least time has SVM and Logistic Regression, both with 11 seconds. 
Although machine learning algorithms are very useful, with these tables we can find out which algorithm will fit the dataset and will be more useful for solving our problems.


## References
[1] Mu√±oz L√≥pez, M. Predictor para el S√≠ndrome de Lynch: Comparativa y an√°lisis de algoritmos de 
machine learning.
[2 ]Zubiaga, A., Fresno, V., & Mart√≠nez, R. (2009). Comparativa de Aproximaciones a SVM Semisupervisado Multiclase para Clasificaci√≥n ÃÅon de P√°ginas Web. Procesamiento del lenguaje natural, (42), 63-70.
[3] Garre, M., Cuadrado, J. J., Sicilia, M. A., Rodr√≠guez, D., & Rejas, R. (2007). Comparaci√≥n de diferentes algoritmos de clustering en la estimaci√≥n de coste en el desarrollo de software. REICIS. Revista Espa√±ola de Innovaci√≥n, Calidad e Ingenier√≠a del Software, 3(1), 6-22.
[4] Safavian, S.R., Landgrebe, D.: A survey of decision tree classifier methodology. IEEE transactions on systems, man, and cybernetics 21(3), 660‚Äì674 (1991)
[5] G. R. Dattatreya and L. N. Kanal, " Decision trees in pattern recognition," In Progress in Pattern Recognition 2, Kanal and Rosenfeld (eds.) , Elsevier Science Publisher B.V., 189-239 (1985).
[6] Betancourt, G. A. (2005). Las m√°quinas de soporte vectorial (SVMs). Scientia et technica, 1(27).
[7] https://www.uv.mx/anmarin/slides/180205Gonzalez.pdf
[8] Jara Estupi√±an, J., Giral, D., & Mart√≠nez Santa, F. (2016). Implementation of algorithms based on support vector machine (SVM) for electric systems: topic review. Tecnura, 20(48), 149-170.
[9]http://powerhousedm.blogspot.com/2007/10/el-problema-xor.html#:~:text=El%20problema%20XOR,problemas%20de%20reconocimiento%20de%20patrones.&text=El%20resultado%20de%20XOR%20ser%C3%A1,sino%20ser%C3%A1%20Falso%20(0).
[10]https://deepai.org/machine-learning-glossary-and-terms/multilayer-perceptron
[11] https://www.statisticssolutions.com/what-is-logistic-regression/
[12]  [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez
[13] https://archive.ics.uci.edu/ml/datasets/Bank+Marketing.
[14]https://eprints.ucm.es/48800/1/Memoria%20TFM%20Machine%20Learning_Juan_Zamorano_para_difundir%20%282%29.pdf

### Collaborators
* **anahi-17** - [Github](https://github.com/anahi-17)
* **fernando-123** - [Github](https://github.com/fernando-123)

